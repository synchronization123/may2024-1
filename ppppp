The error messages you're encountering seem to indicate a couple of issues that need attention. Let's address them step by step:

### 1. Typo in Function Call:
The error message `File spliycsv.py line 23 in module split_csv_pandas(input_file, output_prefix num_parts)` suggests there's a typo in the function call. The parameter `num_parts` is missing a comma between `output_prefix` and `num_parts`. Ensure that your function call looks like this:

```python
split_csv_pandas(input_file, output_prefix, num_parts)
```

### 2. Error in `pd.read_csv()`:
The second part of the error message `File splitcsv.py line 4 in split_csv_pandas df=pd.rrad_csv(input_file)` indicates an issue with `pd.read_csv()` function call. There's a typo in `pd.rrad_csv`, it should be `pd.read_csv`. Additionally, you should handle the potential memory issues by adjusting `chunksize` and setting `low_memory=True`.

### Corrected Code with Fixes:

Hereâ€™s how your script should look after addressing these issues:

```python
import pandas as pd
import os

# Function to split a large CSV file into equal parts using pandas with chunking
def split_csv_pandas(input_file, output_prefix, num_parts):
    # Define chunk size based on estimated number of rows to fit comfortably in memory
    chunk_size = 10**6  # Adjust as needed based on your system's memory capacity

    # Reading CSV file in chunks
    chunks = pd.read_csv(input_file, chunksize=chunk_size, low_memory=True)
    
    part_number = 1
    for chunk in chunks:
        # Calculate rows per part
        rows_per_part = len(chunk) // num_parts
        
        for i in range(num_parts):
            start_index = i * rows_per_part
            end_index = (i + 1) * rows_per_part if i < num_parts - 1 else None
            part_df = chunk.iloc[start_index:end_index]
            
            # Write each part to a new CSV file
            part_filename = f"{output_prefix}_part{part_number}.csv"
            part_df.to_csv(part_filename, index=False)
            part_number += 1
    
    print(f"File split into {num_parts} parts successfully.")

# Example usage:
input_file = 'your_large_file.csv'  # Replace with your file path
output_prefix = 'output_split'      # Prefix for output files
num_parts = 6                       # Number of parts to split into

split_csv_pandas(input_file, output_prefix, num_parts)
```

### Explanation:

- **Chunk Size and `low_memory=True`**: These settings help handle large CSV files more efficiently by reading them in manageable chunks and optimizing memory usage.
  
- **Function Call**: Ensure that the function call `split_csv_pandas(input_file, output_prefix, num_parts)` correctly passes all three parameters (`input_file`, `output_prefix`, `num_parts`) separated by commas.

### Notes:

- **Adjust Chunk Size**: Depending on your system's memory capacity and the size of your CSV file, adjust `chunk_size` (`10**6` in the example) accordingly for optimal performance.
  
- **File Paths**: Replace `'your_large_file.csv'` and `'output_split'` with your actual file path and desired output prefix.

By following these corrected steps and ensuring the function call and `pd.read_csv()` parameters are correctly set, you should be able to successfully split your large CSV file into multiple parts without encountering the previous errors.